{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70c54c0",
   "metadata": {},
   "source": [
    "## Protein Generation and Filtering with BioNeMo\n",
    "\n",
    "This example notebook shows how to generate protein sequences using ProtGPT2 inference from BioNemo service API. For more details, please visit the NVIDIA BioNeMo Service homepage at https://www.nvidia.com/en-us/gpu-cloud/bionemo/\n",
    "\n",
    "This notebook will walk through a protein generation and filtering workflow in the following sections:\n",
    "\n",
    " - **BioNeMo Service Configuration**\n",
    "   - Install dependencies and define the BioNeMo service endpoint and API key required for access\n",
    " - **Generating Protein Sequences**\n",
    "   - Use BioNeMo Service to generate protein sequences with the ProtGPT2 model\n",
    " - **Predict the properties of the generated sequences**\n",
    "   - Use [PGP](https://github.com/hefeda/PGP) to understand the properties of the generated sequences\n",
    "\n",
    "### BioNeMo Service Configurations\n",
    "To get started, please configure and provide your NGC access token by visiting https://ngc.nvidia.com/setup/api-key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0bd263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_KEY=\"YOUR KEY HERE\"\n",
    "API_HOST=\"https://api.bionemo.ngc.nvidia.com/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93a696",
   "metadata": {},
   "source": [
    "Let's start by installing and importing library dependencies. We'll also use _requests_ to interact with the BioNeMo service, and _BioPython_ to parse FASTA sequences into SeqRecord objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0acc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b9fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac22c4-d655-418c-b9d4-f8114ba27321",
   "metadata": {},
   "source": [
    "Next, we can configure the BioNeMo Service Client and validate our connection to the BioNeMo service host.  The BioNeMo Service Client is a Python interface to the BioNeMo Service API, exposing easy-to-use Python functions that allow users to direct access to state-of-the-art models with minimal configuration.  The BioNeMo Service Client is installed with a simple `pip install bionemo` and has been preinstalled in this container.\n",
    "\n",
    "To get started, we'll first instantiate the BioNeMo Service Client with our API_KEY and API_HOST defined above, and then query the service for the list of available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fad16-3218-4e40-9144-8e383542ef7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bionemo.api import BionemoClient\n",
    "api = BionemoClient(api_key=API_KEY, api_host=API_HOST)\n",
    "models=api.list_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79537b9-41f9-4fcf-b334-1d83c6493628",
   "metadata": {
    "tags": []
   },
   "source": [
    "The BioNeMo Python client offers two methods for querying BioNeMo Service:\n",
    " - _sychronous_, in which the service API call will block until a result is returned.\n",
    " - _asynchronous_ or nonblocking, which immediately return a handle called a _correlation_id_ that can be used to query the results.\n",
    "\n",
    "The BioNeMo Python client calls can be differentiated by their name.  Blocking _synchronous_ calls use the `_sync` suffix: `{model_id}_sync`, whereas non-blocking _asynchronous_ calls use the `_async` suffix: `{model_id}_async`.\n",
    "\n",
    "In the following example, our main call into BioNeMo service is to generate candidate protein sequences using ProtGPT2.  Since this is done in a single request, we will use a blocking call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f33be",
   "metadata": {},
   "source": [
    "## Unconditionally generating protein sequences\n",
    "BioNeMo exposes [ProtGPT2](https://www.nature.com/articles/s41467-022-32007-7) as a service for unconditional protein generation. The service can be queried to generate sequences following natural sequence distributions as present in UniProt. These sequences can then be used as the starting point for a [drug discovery campaign](https://www.sciencedirect.com/science/article/pii/S2001037022005086#s0020), which we'll look into in the next chapters of this notebook.\n",
    "\n",
    "It's important to choose your parameters for the protein generation process carefully.\n",
    "\n",
    "-   max_length: maximum number of generated tokens.\n",
    "        \n",
    "Note that common tokens in ProtGPT3 are k-mers of length 3, so 1 token = 3 amino acids. In other words, a max_length=400 could translate to an effective protein sequence of up to 1200 amino acids.\n",
    "\n",
    "- top_k: Sets the number of highest probability vocabulary tokens to keep for top-k-filtering\n",
    "- repetition_penalty: Sets the penalty for [repeating tokens](https://arxiv.org/pdf/1909.05858.pdf), where a value of 1 correspond to no penalty.\n",
    "- num_return_sequences: The effective number of whole protein sequences to return\n",
    "- percent_to_keep: Sets the percent of whole protein sequences to keep for each protein generation iteration cycle, based on their cumulative perplexity. \n",
    "\n",
    "As an illustrative example, suppose that 50 sequences of tokens are generated per itration. From these generated sequences of tokens (which could contain protein sequence fragments or other invalid # sequences), whole protein sequences are reconstructed. Let's suppose that there are 43 valid, whole protein sequences from the generative iteration. Of these 43 whole protein sequences, only the top `percent_to_keep`, according to perplexity, are kept. For instance, with percent_to_keep=10, only ~4 of the 43 sequences (i.e., ~10% of 43) will be kept. After these 4 sequences are added to the return object, the generation process will resume until `num_return_sequences` is reached. Therefore - the lower the value of `percent_to_keep`, the longer the overall generation process will take.\n",
    "\n",
    "We'll use these parameters as an example in the call to ProtGPT2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecac8d-d3be-4641-bb4b-9d582e5fe35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = api.protgpt2_sync(\n",
    "    max_length=400,\n",
    "    top_k=950,\n",
    "    repetition_penalty=1.2,\n",
    "    num_return_sequences=100,\n",
    "    percent_to_keep=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1bc59",
   "metadata": {},
   "source": [
    "Next let's convert the generated sequences into SeqRecord items, so that we can store them in FASTA file locally for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the request response into biopython seqrecords\n",
    "seqrecords = list()\n",
    "\n",
    "for i, (perplexity, sequence) in enumerate(\n",
    "    zip(result['perplexities'], result['generated_sequences'])\n",
    "):\n",
    "    seqrecords.append(SeqRecord(id=f\"S{i+1}\", seq=Seq(sequence), description=f\", L={len(sequence)}, ppl={perplexity}\"))\n",
    "    \n",
    "# Write the sequences to a fasta file\n",
    "sequences_filename = \"data/sequences.fasta\"\n",
    "with open(sequences_filename, \"w\") as output_handle:\n",
    "    SeqIO.write(seqrecords, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da8010",
   "metadata": {},
   "source": [
    "Let's take a look at the saved FASTA file for a quick sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print header lines from protein FASTA file\n",
    "!head data/sequences.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b79905",
   "metadata": {},
   "source": [
    "## Predicting properties from generated protein sequences using PGP\n",
    "[PGP](https://github.com/hefeda/PGP) is an open-source tool that can be used to rapidly analyze protein sequences to predict properties such as secondary structure, gene ontology, subcellular localization, and [more](https://www.sciencedirect.com/science/article/pii/S2001037022005086#s0020).\n",
    "\n",
    "We will use [PGP](https://github.com/hefeda/PGP) here to analyze the sequences generated with ProtGPT2 above to get a better understanding of their properties and the occurrence of desired features.\n",
    "\n",
    "To begin, we need to clone the PGP repository locally and install its dependencies and run the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the PGP repository locally\n",
    "!git clone https://github.com/hefeda/PGP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fc60c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  Note:  PGP relies on <em>torch</em>. If the library isn't already installed on your system, expect the following step to take tens of minutes to download and install all dependencies.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab53088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the minimal requirements\n",
    "!pip install -r data/pgp-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict features using PGP\n",
    "!python PGP/prott5_batch_predictor.py --input data/sequences.fasta --output predictions --fmt ss,cons,dis,mem,bind,go,subcell,tucker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8ae9f",
   "metadata": {},
   "source": [
    "## Reading predictions and querying sequences based on desired properties\n",
    "Lastly, we will load the predicted properties and use them to query the sequences for desired features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PGP.notebooks.utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_features = load_data(pathlib.Path('predictions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c23c88",
   "metadata": {},
   "source": [
    "## Short sequences without transmembrane strands, binding to small molecules\n",
    "\n",
    "In the example above, we limited our ProtGPT2 request to generate only 100 sequences to minimize runtime.  In a production workflow, we would typically work with more complex queries on a much larger generated dataset of sequences.  To increase the likelihood of finding a complex, pharmacologically relevant sequence in our smaller sample set, we will query for sequences that:\n",
    "- Are longer than 100 residues\n",
    "- Do not include transmembrane strand content\n",
    "- Bind to small molecules\n",
    "\n",
    "Lastly we return the sequences ordered by longest sequences with most transmembrane and small molecule binding content. We will print the first ten sequences here. Take a look at the query body for some of the example features that can be inspected, and feel free to manipulate them to change your filtered sequence set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_order = ['length', 'transmembrane_strand_percent', 'small_percent']\n",
    "\n",
    "for sequence in predicted_features.query(\n",
    "    '''\n",
    "    length > 100 and\\\n",
    "    transmembrane_strand_count == 0  and\\\n",
    "    small_count > 0 \n",
    "    '''\n",
    ")[:9].sort_values(filtering_order, ascending=False).to_records():\n",
    "    print(f\"Header: {sequence.header}\")\n",
    "    print(f\"Sequence length: {sequence.length}\")\n",
    "    print(f\"Transmembrane strand content: {sequence.transmembrane_strand_percent*100:0.2f}%\")\n",
    "    print(f\"Small-molecule binding content: {sequence.small_percent*100:0.2f}%\")\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9c548",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we've walked through an example workflow generating protein sequences and analyzing their properties for desired features, covering:\n",
    "\n",
    " - How to configure the BioNeMo Service API\n",
    " - Generating protein sequences with the ProtGPT2 model\n",
    " - Understand the properties of the generated sequences using PGP\n",
    "   \n",
    "While this notebook demonstrates some of the rich capabilities of the BioNeMo service, this would just be the beginning of a production end-to-end drug discovery pipeline. As a next step, consider using the BioNeMo folding services to predict the structures of the sequences you generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25cfad3-2432-4389-81be-ad9c8ebbc004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
